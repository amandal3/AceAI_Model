{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup & Training Script\n",
    "To be run after new videos are added\n",
    "\n",
    "Based on the article [Guide to Build Video Classification Model](https://www.analyticsvidhya.com/blog/2019/09/step-by-step-deep-learning-tutorial-video-classification-python/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/site-packages (4.1.1.26)\r\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Users/amandaly/Library/Python/3.7/lib/python/site-packages (from opencv-python) (1.17.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os, os.path\n",
    "import cv2  # for caputring videos\n",
    "import math # for mathematical operations\n",
    "import matplotlib.pyplot as plt # for plotting the images\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np # for mathematical operations\n",
    "from keras.utils import np_utils\n",
    "from numpy import genfromtxt\n",
    "from skimage.transform import resize # for resizing images\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize \n",
    "from glob import glob\n",
    "import os, os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Turn the csv files into dictionaries\n",
    "1. Opens and converts csv file\n",
    "2. Gets tags\n",
    "3. Gets points for each frame\n",
    "4. Reshapes each frame array\n",
    "5. Groups frames by three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# going into folder with training data\n",
    "path=\"dataPoints_training/\"\n",
    "\n",
    "# creating a pandas dataframe \n",
    "train = pd.DataFrame()\n",
    "\n",
    "# going into individual files\n",
    "for filename in glob(os.path.join(path, '*.csv')):\n",
    "    # go into each file and add all of the data into the train dataframe\n",
    "    file = filename.split(\"/\")[1]  # gets individual file name\n",
    "    train = pd.read_csv(path + file, header=None)  # adds data to dataframe\n",
    "\n",
    "    # creating empty dictionary named trainingFrames_FILENAME\n",
    "    locals()['trainingFrames{}'.format(\"_\" + file.split(\".csv\")[0])] = {}\n",
    "    # creating empty dictionary named trainingCombo_FILENAME\n",
    "    locals()['trainingCombo{}'.format(\"_\" + file.split(\".csv\")[0])] = {}\n",
    "    \n",
    "    #getting tag for each set of points from name of file\n",
    "    tag = filename.split(\"/\")[1].split(\"_\")[3].split(\".csv\")[0]\n",
    "    # creating tag key for each trainingCombo dictionary and adding tag value\n",
    "    locals()['trainingCombo{}'.format(\"_\" + file.split(\".csv\")[0])][\"tag\"] = tag\n",
    "\n",
    "\n",
    "    # number of points per frame\n",
    "    n = 12\n",
    "    \n",
    "    # create array for each frame and adds them to dictionary\n",
    "    for i in range(len(train) // 12):\n",
    "        # grouping each frame and making one big array (with 12 x,y points) aka grouping 12 arrays into one array\n",
    "        data = train.to_numpy()[i * n:(i + 1) * n]\n",
    "        # deleting frame number from above array\n",
    "        data = np.delete(data, 0, 1)\n",
    "        # reshaping each frame array into 24, 1\n",
    "        data = np.reshape(data, (24, 1))\n",
    "        # creating tag with name of number of frame and adding above array as value into trainingFrames\n",
    "        locals()['trainingFrames{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(i)] = data\n",
    "        \n",
    "\n",
    "    # goes into each trainingFrame dictionary\n",
    "    for i in locals()['trainingFrames{}'.format(\"_\" + file.split(\".csv\")[0])]:\n",
    "        # if the point (???) is \n",
    "        if int(i) < (len(locals()['trainingFrames{}'.format(\"_\" + file.split(\".csv\")[0])]))-3:\n",
    "            # counters for one and two above current frame respectively\n",
    "            j = int(i)+1\n",
    "            k = int(i)+2\n",
    "            \n",
    "            # creating local varriables that store current frame array and the two following\n",
    "            combine = locals()['trainingFrames{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(i)]\n",
    "            combineTwo = locals()['trainingFrames{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(j)]\n",
    "            combineThree = locals()['trainingFrames{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(k)]\n",
    "            \n",
    "            # appending current frame with the following two frames\n",
    "            combine = np.append(combine, combineTwo, axis=1)\n",
    "            combine = np.append(combine, combineThree, axis=1)\n",
    "            \n",
    "            # creating tag with name of number of frame and adding above combo into trainingCombo\n",
    "            locals()['trainingCombo{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(i)] = combine  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the same for test videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"dataPoints_test/\"\n",
    "\n",
    "test = pd.DataFrame()\n",
    "\n",
    "for filename in glob(os.path.join(path, '*.csv')):    \n",
    "    file = filename.split(\"/\")[1]\n",
    "    test = pd.read_csv(path + file, header=None)\n",
    "    locals()['testFrames{}'.format(\"_\" + file.split(\".csv\")[0])] = {}\n",
    "    locals()['testCombo{}'.format(\"_\" + file.split(\".csv\")[0])] = {}\n",
    "        \n",
    "    size = len(test[0]) // 12\n",
    "    \n",
    "    for i in range((len(test) + 12 - 1) // 12):\n",
    "        data = test.to_numpy()[i * n:(i + 1) * n]\n",
    "        data = np.delete(data, 0, 1)\n",
    "        data = np.reshape(data, (24, 1))\n",
    "        locals()['testFrames{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(i)] = data\n",
    "\n",
    "    for i in locals()['testFrames{}'.format(\"_\" + file.split(\".csv\")[0])]:                \n",
    "        if int(i) < len(locals()['testFrames{}'.format(\"_\" + file.split(\".csv\")[0])])-3:\n",
    "            j = int(i)+1\n",
    "            k = int(i)+2\n",
    "            \n",
    "            combine = locals()['testFrames{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(i)]\n",
    "            combineTwo = locals()['testFrames{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(j)]\n",
    "            combineThree = locals()['testFrames{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(k)]\n",
    "            \n",
    "            combine = np.append(combine, combineTwo, axis=1)\n",
    "            combine = np.append(combine, combineThree, axis=1)\n",
    "            \n",
    "            locals()['testCombo{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(i)] = combine            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put all the training frames into a dummy thicc array and make them tags numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# going into folder with training data\n",
    "path=\"dataPoints_training/\"\n",
    "\n",
    "# create two empty arrays\n",
    "points = []\n",
    "tags = []\n",
    "\n",
    "# going into individual files\n",
    "for filename in glob(os.path.join(path, '*.csv')): \n",
    "    # go into each file and add all of the data into the train dataframe\n",
    "    file = filename.split(\"/\")[1]\n",
    "    \n",
    "    size = len(locals()['trainingCombo{}'.format(\"_\" + file.split(\".csv\")[0])])\n",
    "    \n",
    "    for i in range(0, size-1):\n",
    "        val = list(locals()['trainingCombo{}'.format(\"_\" + file.split(\".csv\")[0])][\"{}\".format(i)])\n",
    "        points.append(val)\n",
    "    \n",
    "    # add a tag for each frame in trainingCombo (??)\n",
    "    for i in range(0, size-1):\n",
    "        tags.append(locals()['trainingCombo{}'.format(\"_\" + file.split(\".csv\")[0])][\"tag\"])\n",
    "\n",
    "X = np.array(points)\n",
    "\n",
    "tags = pd.DataFrame(tags)\n",
    "\n",
    "# replace tags of \"b\" or \"g\" with 1 and 0. (1 represents bad and g represents good)\n",
    "tags = tags.replace(\"b\", 1)\n",
    "tags = tags.replace(\"g\", 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://www.bitdegree.org/learn/train-test-split\n",
    "# discuss more in depth with RW\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, tags, test_size=0.2)    # preparing the validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape into single dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_valid.shape\n",
    "X_train = X_train.reshape(199, 24*3)\n",
    "X_valid = X_valid.reshape(50, 24*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize me \n",
    "X_train = X_train/X_train.max()      \n",
    "X_valid = X_valid/X_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build dat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer((24*3,)))    # input layer\n",
    "model.add(Dense(units=10, activation='sigmoid', input_shape=(24*3,))) # hidden layer\n",
    "model.add(Dense(2, activation='softmax'))    # output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 10)                730       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 752\n",
      "Trainable params: 752\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to save the weights of best model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "mcp_save = ModelCheckpoint('weight.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create train dataframe\n",
    "# path=\"dataPoints_training/\"\n",
    "\n",
    "# train = pd.DataFrame(columns=[\"file\", \"tag\"])\n",
    "\n",
    "# for filename in glob(os.path.join(path, '*.csv')):    \n",
    "#     file = filename.split(\"/\")[1]\n",
    "    \n",
    "#     size = len(locals()['trainingCombo{}'.format(\"_\" + file.split(\".csv\")[0])])\n",
    "    \n",
    "#     category = locals()['trainingCombo{}'.format(\"_\" + file.split(\".csv\")[0])][\"tag\"]\n",
    "    \n",
    "#     if category is \"b\":\n",
    "#         category = 1\n",
    "#     else:\n",
    "#         category = 0\n",
    "    \n",
    "#     for i in range(0, size-1):\n",
    "        \n",
    "#         train = train.append({\"file\": file, \"tag\": category}, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "# for filename in glob(os.path.join(path, '*.csv')):    \n",
    "#     file = filename.split(\"/\")[1]\n",
    "#     convertFile = pd.read_csv(path + file, header=None)\n",
    "#     locals()['trainingFrames{}'.format(\"_\" + file.split(\".csv\")[0])] = {}\n",
    "#     locals()['trainingCombo{}'.format(\"_\" + file.split(\".csv\")[0])] = {}\n",
    "    \n",
    "#     tag = filename.split(\"/\")[1].split(\"_\")[3].split(\".csv\")[0]\n",
    "#     locals()['trainingCombo{}'.format(\"_\" + file.split(\".csv\")[0])][\"tag\"] = tag            \n",
    "        \n",
    "#     size = len(convertFile[0]) // 12\n",
    "       \n",
    "#     n = 12\n",
    "#     for i in range((len(convertFile) + 12 - 1) // 12):\n",
    "#         data = convertFile.to_numpy()[i * n:(i + 1) * n]\n",
    "#         data = np.delete(data, 0, 1)\n",
    "#         data = np.reshape(data, (24, 1))\n",
    "#         locals()['trainingFrames{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(i)] = data\n",
    "\n",
    "#     for i in locals()['trainingFrames{}'.format(\"_\" + file.split(\".csv\")[0])]:                \n",
    "#         if int(i) < (len(locals()['trainingFrames{}'.format(\"_\" + file.split(\".csv\")[0])]))-3:\n",
    "#             j = int(i)+1\n",
    "#             k = int(i)+2\n",
    "            \n",
    "#             combine = locals()['trainingFrames{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(i)]\n",
    "#             combineTwo = locals()['trainingFrames{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(j)]\n",
    "#             combineThree = locals()['trainingFrames{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(k)]\n",
    "                        \n",
    "#             combine = np.append(combine, combineTwo, axis=1)\n",
    "#             combine = np.append(combine, combineThree, axis=1)\n",
    "            \n",
    "#             locals()['trainingCombo{}'.format(\"_\" + file.split(\".csv\")[0])]['{}'.format(i)] = combine         \n",
    "\n",
    "        \n",
    "# print(trainingCombo{})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 199 samples, validate on 50 samples\n",
      "Epoch 1/10\n",
      "199/199 [==============================] - 0s 1ms/step - loss: 0.5597 - accuracy: 0.7437 - val_loss: 0.6006 - val_accuracy: 0.6800\n",
      "Epoch 2/10\n",
      "199/199 [==============================] - 0s 483us/step - loss: 0.5258 - accuracy: 0.7789 - val_loss: 0.6157 - val_accuracy: 0.6800\n",
      "Epoch 3/10\n",
      "199/199 [==============================] - 0s 525us/step - loss: 0.5139 - accuracy: 0.7789 - val_loss: 0.7123 - val_accuracy: 0.6800\n",
      "Epoch 4/10\n",
      "199/199 [==============================] - 0s 487us/step - loss: 0.5087 - accuracy: 0.7789 - val_loss: 0.5916 - val_accuracy: 0.6800\n",
      "Epoch 5/10\n",
      "199/199 [==============================] - 0s 482us/step - loss: 0.5047 - accuracy: 0.7789 - val_loss: 0.8922 - val_accuracy: 0.6800\n",
      "Epoch 6/10\n",
      "199/199 [==============================] - 0s 610us/step - loss: 0.4937 - accuracy: 0.7789 - val_loss: 0.7155 - val_accuracy: 0.6800\n",
      "Epoch 7/10\n",
      "199/199 [==============================] - 0s 535us/step - loss: 0.4850 - accuracy: 0.7789 - val_loss: 0.9694 - val_accuracy: 0.6800\n",
      "Epoch 8/10\n",
      "199/199 [==============================] - 0s 496us/step - loss: 0.4740 - accuracy: 0.7789 - val_loss: 0.6296 - val_accuracy: 0.6800\n",
      "Epoch 9/10\n",
      "199/199 [==============================] - 0s 467us/step - loss: 0.4674 - accuracy: 0.7789 - val_loss: 0.6802 - val_accuracy: 0.6800\n",
      "Epoch 10/10\n",
      "199/199 [==============================] - 0s 467us/step - loss: 0.4532 - accuracy: 0.7789 - val_loss: 1.1041 - val_accuracy: 0.6800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x11dfdcdd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=10, validation_data=(X_valid, y_valid), callbacks=[mcp_save], batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does this show us?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "77.89% Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
